#!/usr/bin/env python3
"""
Script pour convertir le dataset Kaggle US Accidents CSV en JSON
Usage: python convert_dataset.py
"""

import pandas as pd
import json
import os

# Chemin du fichier CSV
CSV_PATH = r"C:\Users\moham\Downloads\archive (1)\US_Accidents_March23.csv"
OUTPUT_PATH = "us_accidents_sample.json"

print("ðŸ”„ Converting Kaggle US Accidents dataset...")
print(f"ðŸ“‚ Input: {CSV_PATH}")
print(f"ðŸ“‚ Output: {OUTPUT_PATH}\n")

try:
    # Lire le CSV (peut Ãªtre trÃ¨s volumineux)
    print("ðŸ“– Reading CSV file (this may take a while for large files)...")
    df = pd.read_csv(CSV_PATH)
    
    print(f"âœ… Loaded {len(df)} accident records")
    print(f"ðŸ“Š Columns: {list(df.columns[:10])}...")  # Show first 10 columns
    
    # Prendre un Ã©chantillon pour rÃ©duire la taille (optionnel mais recommandÃ©)
    # Le dataset complet peut Ãªtre trÃ¨s volumineux (>2GB)
    SAMPLE_SIZE = 50000  # 50k accidents pour l'entraÃ®nement
    
    if len(df) > SAMPLE_SIZE:
        print(f"\nðŸ“‰ Sampling {SAMPLE_SIZE} records from {len(df)} total records...")
        df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)
    else:
        df_sample = df
        print(f"\nâœ… Using all {len(df)} records")
    
    # SÃ©lectionner les colonnes importantes
    required_columns = ['Start_Lat', 'Start_Lng', 'Severity']
    optional_columns = ['Start_Time', 'Temperature(F)', 'Humidity(%)', 'Visibility(mi)', 'Weather_Condition']
    
    # VÃ©rifier quelles colonnes existent
    available_cols = [col for col in required_columns + optional_columns if col in df_sample.columns]
    df_clean = df_sample[available_cols].copy()
    
    # Nettoyer les donnÃ©es
    print("\nðŸ§¹ Cleaning data...")
    # Supprimer les lignes avec coordonnÃ©es invalides
    df_clean = df_clean.dropna(subset=['Start_Lat', 'Start_Lng'])
    # Filtrer les coordonnÃ©es valides (USA: lat 24-50, lon -125 Ã  -66)
    df_clean = df_clean[
        (df_clean['Start_Lat'] >= 24) & (df_clean['Start_Lat'] <= 50) &
        (df_clean['Start_Lng'] >= -125) & (df_clean['Start_Lng'] <= -66)
    ]
    
    print(f"âœ… Cleaned data: {len(df_clean)} valid records")
    
    # Convertir en format JSON
    print("\nðŸ’¾ Converting to JSON...")
    records = df_clean.to_dict('records')
    
    # Sauvegarder en JSON
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(records, f, indent=2, ensure_ascii=False)
    
    file_size = os.path.getsize(OUTPUT_PATH) / (1024 * 1024)  # MB
    print(f"\nâœ… Conversion complete!")
    print(f"ðŸ“ Output file: {OUTPUT_PATH}")
    print(f"ðŸ“Š Records: {len(records)}")
    print(f"ðŸ’¾ File size: {file_size:.2f} MB")
    print(f"\nðŸŽ¯ Next steps:")
    print(f"   1. Open train-model.html in your browser")
    print(f"   2. Click 'Start Training'")
    print(f"   3. Wait for training to complete")
    print(f"   4. The model will be saved and ready to use!")
    
except FileNotFoundError:
    print(f"âŒ Error: File not found at {CSV_PATH}")
    print(f"   Please check the path and try again")
except Exception as e:
    print(f"âŒ Error: {e}")
    import traceback
    traceback.print_exc()

